# 주식 투자 패턴 종류

<details>
  <summary style="font-size: 1.2em;">퀀트 투자법 & 기술적 분석</summary> </br>
    퀀트 투자법과 기술적 분석은 주식 투자에서 널리 사용되는 주류 패턴입니다. 이 두 방법은 데이터 기반의 접근 방식을 통해 투자 결정을 내리는 데 도움을 줍니다.

* 퀀트 투자법
  * 수학적 모델과 통계적 기법을 활용하여 투자 기회를 식별합니다.
  * 대량의 데이터를 분석하여 객관적인 투자 결정을 내립니다.
  * 주가 변동 패턴을 탐지하고 이를 기반으로 투자 유형을 추천합니다.

* 기술적 분석
  * 과거 주가와 거래량 데이터를 분석하여 미래 가격 움직임을 예측합니다.
  * 차트 패턴, 기술적 지표, 추세선 등을 활용합니다.
  * 빈번하게 발생하는 주가 변화 패턴을 식별하고 이를 투자 결정에 활용합니다.

* 두 방법의 공통점
  * 데이터 기반의 객관적인 접근 방식을 사용합니다.
  * 과거 데이터를 분석하여 미래 주가 움직임을 예측하려고 시도합니다.
  * 컴퓨터 알고리즘과 자동화된 시스템을 활용하여 효율적인 분석을 수행합니다.

* 두 방법의 차이점
  * 퀀트 투자법은 더 복잡한 수학적 모델을 사용하는 경향이 있습니다.
  * 기술적 분석은 주로 가격과 거래량 데이터에 집중하는 반면, 퀀트 투자법은 더 다양한 데이터 소스를 활용할 수 있습니다.

이러한 주류 패턴들은 개인 투자자의 심리적 특성이나 행동 패턴을 고려하는 행동 재무학 기반 투자와는 달리, 객관적인 데이터에 더 중점을 둡니다. 또한, 강화학습 기반의 동적 자산 할당 기법과 같은 최신 기술을 활용한 방법들과 비교했을 때, 상대적으로 전통적이고 널리 사용되는 접근 방식입니다.
</details>

<details>
  <summary style="font-size: 1.2em;">행동 재무학 기반 투자</summary> </br>
    행동 재무학 기반 투자는 투자자의 심리적 특성과 행동 패턴을 고려하는 비주류 투자 방법입니다. 이 접근 방식은 전통적인 재무 이론과 달리 투자자의 비합리적 행동을 인정하고 이를 투자 전략에 반영합니다.

* 과잉 거래와 수익률 관계
  * 개인 투자자의 거래 빈도가 증가할수록 투자 수익률이 저하되는 경향이 있습니다.
  * 이는 과도한 거래 비용과 시장 타이밍의 실패로 인한 결과로 볼 수 있습니다.

* 과잉 확신의 영향
  * 자신의 투자 능력에 대한 확신이 증가할수록 수익률이 감소하는 현상이 관찰됩니다.
  * 과잉 확신은 과도한 거래를 유발하고, 이는 결과적으로 수익률 저하로 이어집니다.

* 성격 요인의 역할
  * 외향성이 높은 투자자들은 과도한 거래를 하는 경향이 있어 수익률이 떨어질 수 있습니다.
  * 이는 외향적인 성격이 더 활발한 투자 활동으로 이어질 수 있음을 시사합니다.

* 행동 재무학 기반 투자 전략
  * 투자자의 심리적 편향을 인식하고 이를 극복하는 방법을 개발합니다.
  * 시장의 비효율성을 활용하여 투자 기회를 포착하려고 시도합니다.
  * 장기적인 투자 관점을 유지하고 감정적 결정을 최소화하는 전략을 수립합니다.

* 행동 재무학의 한계
  * 개인차가 크기 때문에 일반화된 전략 수립이 어려울 수 있습니다.
  * 투자자의 심리 상태를 정확히 측정하고 예측하는 것이 쉽지 않습니다.

행동 재무학 기반 투자는 투자자의 심리와 행동을 이해함으로써 더 나은 투자 결정을 내리는 데 도움을 줄 수 있습니다. 그러나 이 접근 방식은 여전히 발전 중이며, 전통적인 투자 방법과 병행하여 사용되는 경우가 많습니다.
</details>

<details>
  <summary style="font-size: 1.2em;">강화 학습 및 뉴스 분석</summary> </br>
    강화학습과 뉴스 분석은 주식 투자에서 새롭게 주목받고 있는 비주류 패턴입니다. 이 방법들은 전통적인 투자 방식에 인공지능과 빅데이터 분석을 접목시켜 더 효과적인 투자 전략을 수립하는 데 활용됩니다.

* 강화학습 기반 동적 자산 할당
  * 다수의 주가 예측 모델을 결합하여 거래 성능을 최대화합니다.
  * 메타 정책(meta policy)이라는 자산 할당 정책을 강화 학습 틀 내에서 정의합니다.
  * 각 예측 모델의 추천 종목 수와 전체 자산 대비 주식 자금 비율을 동시에 활용하는 상태 공간을 설계합니다.
  * 기존의 고정 자산 할당 방법들보다 우수한 성능을 보입니다.

* 뉴스 분석을 통한 투자 전략
  * 실시간 뉴스 데이터를 분석하여 시장 동향을 파악합니다.
  * 자연어 처리 기술을 활용하여 뉴스의 감성(sentiment)을 분석합니다.
  * 특정 기업이나 산업에 대한 긍정적/부정적 뉴스가 주가에 미치는 영향을 예측합니다.

* 패턴 기반 예측 모델
  * 과거 주가 변화 패턴을 분석하여 투자 유형을 추천합니다.[2]
  * 빈번하게 발생하는 주가 변화 패턴의 이후 경향을 투자자의 조건과 매칭합니다.
  * 효율적인 규칙 탐사와 매칭을 위해 빈번 패턴 베이스를 구축하고 인덱싱합니다.

* 강화학습과 뉴스 분석의 장점
  * 시장의 복잡성과 동적 특성을 더 잘 반영할 수 있습니다.
  * 실시간 데이터를 활용하여 빠르게 변화하는 시장 상황에 대응할 수 있습니다.
  * 인간의 편향을 줄이고 객관적인 의사결정을 지원합니다.

* 한계점
  * 복잡한 알고리즘과 대량의 데이터 처리가 필요하여 개인 투자자가 활용하기 어려울 수 있습니다.
  * 과거 데이터에 기반한 학습이므로 예측하지 못한 시장 변화에 취약할 수 있습니다.
  * 모델의 '블랙박스' 특성으로 인해 투자 결정의 근거를 명확히 설명하기 어려울 수 있습니다.

이러한 비주류 패턴들은 전통적인 투자 방법과 결합하여 사용될 때 더욱 효과적일 수 있으며, 지속적인 연구와 발전이 이루어지고 있는 분야입니다.
</details>

<details>
  <summary style="font-size: 1.2em;">딥러닝 기반 예측 모델에 적용</summary> </br>
    LSTM(Long Short-Term Memory) 모델은 주식 시장 분석 및 예측에 있어 다양한 장단점을 가지고 있습니다. 각 투자 방법론에 대한 LSTM의 적용 가능성과 한계점을 살펴보겠습니다.

* 퀀트 투자법과의 연관성
  - LSTM은 대량의 시계열 데이터를 처리하는 데 탁월하여 퀀트 투자에 적합합니다.
  - 복잡한 비선형 패턴을 포착할 수 있어 전통적인 통계 모델보다 우수한 성능을 보일 수 있습니다.
  - 그러나 모델의 '블랙박스' 특성으로 인해 투자 결정의 근거를 명확히 설명하기 어려울 수 있습니다.

* 기술적 분석과의 적용
  - LSTM은 과거 주가 및 거래량 데이터의 패턴을 학습하여 미래 가격 움직임을 예측하는 데 효과적입니다.
  - 다양한 기술적 지표를 입력으로 사용하여 복잡한 시장 동향을 포착할 수 있습니다.
  - 하지만 극단적인 시장 변동이나 예기치 못한 이벤트에 대한 대응력이 부족할 수 있습니다.

* 행동 재무학 기반 투자와의 관계
  - LSTM은 투자자 심리나 행동 패턴을 직접적으로 모델링하기 어렵습니다.
  - 그러나 거래량, 변동성 등의 지표를 통해 간접적으로 시장 심리를 학습할 수 있습니다.
  - 행동 재무학적 요소를 수치화하여 입력 데이터로 활용한다면 더 나은 예측이 가능할 수 있습니다.

* 강화학습과의 결합
  - LSTM은 강화학습 모델의 상태 표현(state representation)으로 사용될 수 있어, 동적 자산 할당에 효과적입니다.
  - 시계열 데이터의 특성을 잘 포착하여 강화학습 에이전트의 의사결정을 지원할 수 있습니다.
  - 그러나 강화학습과 LSTM의 결합은 모델의 복잡성을 증가시켜 학습과 최적화에 어려움을 줄 수 있습니다.

* 뉴스 분석과의 통합
  - LSTM은 텍스트 데이터 처리에도 사용될 수 있어, 뉴스 기사의 감성 분석에 활용될 수 있습니다.
  - 뉴스 데이터와 주가 데이터를 결합하여 더 포괄적인 시장 분석이 가능합니다.
  - 그러나 실시간 뉴스 처리와 즉각적인 모델 업데이트에는 기술적 한계가 있을 수 있습니다.

LSTM 모델의 주요 한계점:
* 과적합(Overfitting) 위험: 복잡한 모델 구조로 인해 학습 데이터에 과도하게 맞춰질 수 있습니다.
* 해석의 어려움: 모델의 의사결정 과정을 명확히 설명하기 어려워 투자자의 신뢰를 얻기 힘들 수 있습니다.
* 극단적 이벤트 대응: 학습 데이터에 없던 극단적인 시장 상황에 대한 대응력이 부족할 수 있습니다.
* 계산 비용: 대량의 데이터로 학습하고 실시간으로 예측하기 위해서는 상당한 컴퓨팅 리소스가 필요합니다.

LSTM은 시계열 데이터 처리에 강점을 가지고 있어 주식 시장 분석에 유용하게 활용될 수 있지만, 여전히 실제 투자에 적용할 때는 다양한 한계점을 고려해야 합니다. 따라서 LSTM을 다른 분석 방법들과 보완적으로 사용하는 것이 더 효과적일 수 있습니다.
</details>

<details>
  <summary style="font-size: 1.2em;">주식시장 패턴 선호도(추세 분석)</summary> </br>
    주식 시장에서 다양한 분석 패턴의 활용 비율과 효과성은 시장 상황, 투자자 유형, 그리고 시간대에 따라 다양하게 나타납니다. 일반적인 경향과 특정 상황에서의 예외를 살펴보겠습니다.

</br>


* 기술적 분석: 약 40-50%
  - 대부분의 단기 트레이더와 많은 개인 투자자들이 선호합니다.
  - 일반적으로 추세가 명확한 시장에서 효과적입니다.
  - 급격한 시장 변동이나 예상치 못한 이벤트 발생 시 신뢰성이 떨어집니다.

* 퀀트 투자법: 약 20-30%
  - 대형 기관투자자와 헤지펀드에서 주로 사용합니다.
  - 시장이 안정적이고 과거 패턴이 반복될 때 효과적입니다.
  - 극단적인 시장 상황(예: 금융 위기)에서는 모델의 예측력이 저하될 수 있습니다.

* 행동 재무학 기반 투자: 약 10-15%
  - 장기 투자자와 가치 투자자들 사이에서 인기가 있습니다.
  - 시장의 비이성적 행동이 두드러질 때 특히 유용합니다.
  - 시장이 매우 효율적으로 작동하는 기간에는 그 효과가 제한적일 수 있습니다.

* 강화학습 및 AI 기반 분석: 약 5-10%
  - 최근 몇 년간 사용이 증가하고 있으며, 주로 첨단 기술을 보유한 기관에서 활용합니다.
  - 복잡한 시장 패턴을 포착하는 데 효과적입니다.
  - 데이터의 질과 양에 크게 의존하며, 새로운 시장 상황에 적응하는 데 시간이 걸릴 수 있습니다.

* 뉴스 분석: 약 5-10%
  - 고빈도 거래와 이벤트 기반 전략에서 주로 사용됩니다.
  - 시장에 중요한 뉴스가 빈번히 발생할 때 효과적입니다.
  - 뉴스의 영향이 제한적이거나 시장이 뉴스에 둔감할 때는 그 효과가 감소합니다.

각 분석 패턴의 효과성이 떨어지는 특정 구간:

1. 기술적 분석: 
   - 시장이 횡보할 때 신뢰성이 떨어집니다.
   - 중요한 경제 지표 발표나 기업 실적 발표 직전에는 기술적 지표가 무의미해질 수 있습니다.

2. 퀀트 투자법:
   - 시장 구조가 급격히 변화하는 시기(예: 코로나19 팬데믹 초기)에는 과거 데이터 기반 모델의 정확도가 떨어집니다.
   - 정부의 정책 변화나 규제 도입 시 기존 모델의 유효성이 감소할 수 있습니다.

3. 행동 재무학 기반 투자:
   - 시장이 매우 안정적이고 효율적으로 작동할 때는 그 효과가 제한적입니다.
   - 기술 주도의 강세장에서는 전통적인 가치 평가 방식이 무력화될 수 있습니다.

4. 강화학습 및 AI 기반 분석:
   - 학습 데이터에 포함되지 않은 새로운 유형의 시장 상황에서는 성능이 저하될 수 있습니다.
   - 시장의 구조적 변화가 발생할 때 모델의 재학습이 필요하며, 이 기간 동안 예측력이 떨어질 수 있습니다.

5. 뉴스 분석:
   - 시장이 특정 뉴스에 과민 반응하거나 무반응할 때 효과가 떨어집니다.
   - 가짜 뉴스나 루머가 시장을 교란시킬 때 신뢰성 있는 분석이 어려워집니다.

이러한 분석 패턴들은 서로 보완적으로 사용될 때 가장 효과적일 수 있으며, 투자자들은 시장 상황에 따라 적절히 조합하여 사용하는 것이 중요합니다.
</details>

<details>
  <summary style="font-size: 1.2em;">주식 예측 시간 분석</summary> </br>
    주식 예측 모델에서 언급하는 1년 단위나 6개월 단위는 일반적으로 상대적인 기간을 의미합니다. 이는 특정 시점으로부터의 기간을 나타내며, 절대적인 연도를 지칭하지 않습니다.

* 상대적 기간의 의미:
  - 1년 단위: 예측 시점으로부터 향후 1년간의 기간
  - 6개월 단위: 예측 시점으로부터 향후 6개월간의 기간

* 예측 모델의 적용:
  - 롤링 윈도우 방식: 지속적으로 새로운 데이터를 반영하여 예측을 업데이트합니다.
  - 이동 평균: 과거 일정 기간의 데이터를 사용하여 미래를 예측합니다.

* 상대적 기간 사용의 이점:
  - 유연성: 다양한 시점에서 예측을 수행할 수 있습니다.
  - 일관성: 시장 조건의 변화에 따라 모델을 지속적으로 적용할 수 있습니다.
  - 비교 가능성: 서로 다른 시점의 예측 결과를 비교하기 쉽습니다.

* 실제 적용 예시:
  - ARIMA 모델: S&P 500 지수 예측에서 1년 단위로 70% 이상의 정확도를 보였습니다.
  - Prophet 모델: Apple 주식 가격 예측에서 6개월 이내 77%의 정확도를 달성했습니다.

이러한 상대적 기간 접근 방식은 주식 시장의 동적인 특성을 반영하며, 모델의 지속적인 업데이트와 재훈련을 가능하게 합니다. 따라서 주식 예측 모델은 특정 연도가 아닌, 예측 시점으로부터의 상대적인 기간을 기준으로 성능을 평가하고 결과를 제시합니다.
</details>

</br>
</br>

# 제작 모델

주식 예측을 위해 LSTM을 사용하여 특정 주식의 종가를 기반으로 미래 종가가 상승하는지 하락하는지 판단하는 모델을 제작하는 것을 목표로 하였다.

## 모델 아키텍쳐

![img]

## 모델 적용 기술

### 1. 데이터 전처리 및 시계열 데이터 관리

- **Pandas와 Numpy**: 데이터를 DataFrame 형태로 처리하고 차원 변환과 수학 연산을 수행하는 데 사용되었다.
- **결측값 채우기**: 경제 및 경기 지표는 과거 데이터로 결측값을 채우는 **`fillna(method='ffill')`**와 미래 데이터로 채우는 **`fillna(method='bfill')`** 방식을 사용하여 결측값을 보완하였다.
- **스케일링**: 데이터의 정규화를 위해 `StandardScaler`와 `minmax_scale`을 사용하여 평균을 0, 분산을 1로 맞추거나, 특정 범위로 스케일링하였다.
- **시계열 확장**: 월별 또는 분기별 데이터를 일간 데이터로 확장하여 시계열 예측이 가능하도록 처리하였다.

---

### 2. 외부 데이터 수집 및 통합

- **FinanceDataReader & Yahoo Finance API**: 주식, 원유, 금, 환율 데이터 등을 수집하여 모델에 사용하였다.
- **Google Trends (PyTrends)**: 경제, 사회 이슈와 관련된 구글 트렌드 데이터를 수집하여 예측 변수로 추가하였다.
- **FRED API**: 미국 경제 데이터를 가져와 다양한 경제 지표와 연동하였다.
- **PandasDMX**: 다양한 경제 지표를 외부 API에서 쉽게 불러오고 분석할 수 있도록 사용되었다. 또한, 지표를 응용하여 주식의 트랜드와 데이터의 주기를 학습시키는 용도로 사용하였다.

---

### 3. 딥러닝 및 모델 구성

- **PyTorch**: 딥러닝 모델 개발 및 학습을 위한 프레임워크로서, `torch`, `torch.nn`, `torch.optim` 등의 모듈을 사용하여 LSTM 모델과 관련 최적화 알고리즘(예: Adam, AdamW)을 구현하였다.
- **DataLoader 및 TensorDataset**: 데이터를 Tensor 형식으로 변환하고 모델 학습에 필요한 배치 단위로 나누기 위해 활용되었다.
- **torchinfo**: 모델의 구조와 파라미터 수를 확인하고 모델 구성을 검토하는 데 사용되었다.

---

### 4. 하이퍼파라미터 최적화

- **Ray Tune**: `ray` 라이브러리를 통해 하이퍼파라미터 튜닝을 자동화하였으며, 성능 최적화를 위해 다양한 조합을 탐색할 수 있게 하였다.

---

### 5. 성능 평가 및 시각화

- **scikit-learn의 성능 지표**: `accuracy_score`, `f1_score`, `confusion_matrix`, `roc_curve`, `auc`, `mcc` 등을 활용하여 모델의 성능을 평가하고, 이진 분류에서 주가 상승/하락 예측의 정확성을 점검하였다.
- **Seaborn 및 Matplotlib**: 시각화를 통해 데이터 탐색 및 모델 결과를 분석하였으며, 특히 히트맵으로 상관관계를 시각화하였다.
- **tqdm**: 데이터 처리 및 학습 단계의 진행 상황을 실시간으로 보여주어 효율적인 모델 개발 환경을 제공하였다.

---

### 6. 기타 유틸리티 및 환경 설정

- **EasyDict**: 종목코드 및 지표를 관리하기 위해 `EasyDict`을 사용하여 가독성과 관리 효율성을 높였다.
- **Python-dotenv**: `.env` 파일을 사용하여 환경 변수(예: API 키)를 로드하여 코드의 보안성과 유연성을 향상하였다.
- **Google Colab 환경 설정**: Colab에서의 작업을 위해 드라이브를 연결하여 데이터 파일을 저장하고 로드하는 기능을 추가하였다.

---

### 7. 기술적 지표 계산 및 추가

주가 데이터를 분석하기 위해 여러 **기술적 지표**를 추가하였습니다. 각 지표는 `pandas_ta` 라이브러리를 활용해 계산되며, 이는 주가의 이동평균, 상대 강도 지수 등 다양한 시계열 지표를 포함합니다. 구체적으로 적용된 지표는 다음과 같다.

- **단순 이동 평균(SMA)**: 주가의 단순 평균을 구해 추세를 파악하기 위한 지표로, `ta.sma` 함수를 사용하여 추가한다.
- **상대 강도 지수(RSI)**: 과매수 또는 과매도 여부를 측정하여 주가 변동 가능성을 파악한다.
- **지수 이동 평균(EMA)**: 최신 가격에 가중치를 더 부여한 이동 평균을 구한다.
- **볼린저 밴드**: 주가 변동성을 측정하고 이를 통해 주가가 평균으로 회귀하는지 또는 돌파하는지 판단한다.
- **ADX** (평균 방향성 지수): 시장 추세의 강도를 측정한다.
- **MACD** (이동평균 수렴 확산): 단기와 장기 이동평균을 비교해 추세 변화를 감지한다.
- **스토캐스틱 오실레이터**: 현재 가격 위치가 과거 주가 범위 내에서 어느 위치에 있는지를 파악한다.
- **ATR** (평균 실제 범위): 주가 변동성의 범위를 나타내는 지표이다.
- **CCI** (상품 채널 지수): 특정 시점의 가격과 이동평균의 차이를 측정하여 주가의 과매수/과매도를 평가한다.

이 외에도 금, 유가, 환율 등의 경제 지표도 추가하여 모델의 입력 데이터로 사용하였다.

---

### 8. 시계열 데이터셋 구성

- **window_size를 적용한 시계열 데이터셋 생성**: 주가 예측을 위한 시계열 데이터셋을 생성할 때, 일정 기간(window size) 동안의 데이터(feature)와 이후의 target을 설정하여 훈련/테스트 데이터셋을 구성하였다.
- **Sliding Window 방식**: `window_size`에 맞게 일정 기간의 데이터를 슬라이딩 방식으로 추출하여 모델의 입력 데이터로 변환하였다.

---

### 9. API를 통한 데이터 수집 및 저장 자동화

- **API 요청 및 자동화**: 한국은행 ECOS API 등 다양한 데이터 API를 활용하여 경제 지표와 시장 관련 데이터를 수집하고 저장하였다.
- **자동 파일 저장 및 업데이트**: API로 수집한 데이터를 CSV 파일로 저장하여 필요한 시점에 데이터 업데이트가 가능하도록 하였다.
- **.env 파일 사용**: `.env` 파일에 API 키를 저장하고 `dotenv`를 통해 불러오는 방식으로 보안과 유연성을 확보하였다.

---

### 10. LSTM과 BERT 기반 복합 모델 구성

- **LSTM 모델**: 과거 주가 데이터를 입력으로 받아 시계열 예측을 수행하며, 주가의 과거 패턴을 학습하는 역할을 담당한다.
  - **Dropout**: LSTM 레이어 이후와 Fully Connected 레이어 사이에 **Dropout 레이어**를 사용하여 과적합을 방지한다.
  - **ReLU 활성화 함수**: 비선형성을 추가하여 모델의 학습 성능을 향상시키기 위해 ReLU 활성화 함수를 사용하였다.
- **뉴스 데이터 감성 분석 모델**: 뉴스 데이터를 입력으로 받아 감성 분석을 수행하고, 그 결과를 모델의 입력에 추가한다.
  - **BERT**: 사전 학습된 `klue/bert-base` 모델을 활용하여 뉴스 텍스트를 감성 분석하고, 긍정 또는 부정 레이블을 예측하여 이를 모델의 추가 입력으로 사용한다.
  - **뉴스 감성 예측 및 변환**: BERT로부터 나온 감성 예측 결과는 수치 데이터로 변환되며, 이를 주가 예측 모델에 입력으로 사용한다.
- **복합 모델 (Combined Model)**: LSTM의 출력과 뉴스 감성 분석의 출력을 결합한 뒤, 최종 예측값을 도출하는 Fully Connected 레이어를 사용한다.

<details>
  <summary style="font-size: 1.2em;">BERT 모델 설명: 뉴스 감성 분석을 통한 주가 예측 강화</summary> </br>
    
이 프로젝트에서 BERT 모델은 **뉴스 텍스트를 감성 분석**하는 역할을 수행한다. 감성 분석은 뉴스의 내용이 주가에 긍정적인 영향을 미치는지(상승 가능성) 또는 부정적인 영향을 미치는지(하락 가능성)를 판단하여, 최종 주가 예측에 중요한 인풋으로 활용된다. 구체적인 단계와 함께, BERT가 어떻게 감성 분석을 수행하고 결과를 주가 예측에 반영하는지 살펴보자.

---

#### 1. 뉴스 데이터 감성 분석 과정

#### 1.1 BERT 토크나이저를 통한 텍스트 전처리

BERT는 사전 학습된 토크나이저와 언어 모델을 사용하여 **뉴스 텍스트 데이터를 숫자형 벡터로 변환**한다. 
이 과정에서 다음과 같은 단계를 거친다:
   - **토크나이징**: 각 뉴스 텍스트는 BERT 토크나이저(`BertTokenizer`)를 사용하여 단어와 문장을 숫자형 토큰으로 변환한다. 이 토큰은 BERT 모델이 이해할 수 있는 형식이다.
   - **특수 토큰 추가**: 각 입력 텍스트에 `[CLS]` (문장의 시작)와 `[SEP]` (문장의 끝) 토큰을 추가한다. BERT는 `[CLS]` 토큰의 출력을 사용해 문장 전체의 감성을 나타내기 때문에, 이를 통해 텍스트 전체의 감성 분류가 가능하다.
   - **패딩과 트렁케이팅**: 문장의 길이가 다를 수 있으므로, 최대 길이로 설정한 뒤 부족한 길이는 패딩(`[PAD]`) 처리하고, 초과된 길이는 잘라낸다.

#### 1.2 감성 예측을 위한 BERT 모델 로드

감성 분석 모델은 사전 학습된 BERT 기반 `klue/bert-base`를 사용하며, 뉴스 텍스트가 긍정(상승 가능성)인지 부정(하락 가능성)인지를 예측한다.
   - **출력 레이블**: 이 프로젝트에서는 이진 분류를 수행하도록 `TFBertForSequenceClassification`을 `num_labels=2`로 설정해 사용했습니다. 이는 뉴스가 긍정적인지(주가 상승 가능성) 또는 부정적인지(주가 하락 가능성)를 나타낸다.
   - **감성 예측**: 모델의 최종 출력에서 로짓을 소프트맥스(Softmax) 함수를 적용하여 두 클래스의 확률(긍정과 부정)을 반환한다. 그 중 높은 확률을 갖는 클래스가 해당 뉴스의 감성으로 예측된다.

#### 1.3 감성 예측 결과 저장

예측된 감성 레이블은 뉴스 데이터와 함께 데이터프레임에 저장된다. 이 데이터는 이후 주가 예측 모델의 입력으로 사용된다.
   - **CSV 파일로 저장**: 감성 분석 결과는 `news_data_with_sentiment.csv` 파일로 저장되며, 이후 모델 학습 시 기존 감성 데이터를 불러와 사용할 수 있다. 이는 코드에서 `load_sentiment_data()` 함수로 이루어지며, 데이터 재활용을 통해 분석 비용을 절감한다.

---

#### 2. 감성 분석 결과를 주가 예측 모델에 통합

#### 2.1 BERT 감성 분석 결과의 수치적 표현

뉴스 텍스트의 감성 예측 결과는 수치형 데이터로 변환되어 LSTM 기반의 주가 예측 모델에 결합된다.
   - **확률 분포 확장**: 예측된 감성 클래스 확률을 일종의 수치 벡터 형태로 변환하여 모델의 입력으로 확장한다. 코드에서는 `expend_sentiment_data()` 함수를 통해 배치 크기와 시퀀스 길이에 맞춰 수치 벡터로 변환한다.
   - **LSTM 출력과의 결합**: 뉴스 감성 예측 결과는 LSTM으로 분석된 주가 데이터의 최종 출력에 추가적으로 결합된다. 이 결합된 정보는 최종 Fully Connected Layer로 전달되어, 주가 예측의 마지막 단계를 수행한다.

#### 2.2 감성 분석이 주가 예측에 미치는 영향

감성 분석은 **단기적인 주가 변동성을 포착**하는 데 유용하다. 주가는 뉴스의 영향을 크게 받기 때문에, 긍정적인 뉴스는 상승 가능성을 높이고, 부정적인 뉴스는 하락 가능성을 높인다. BERT 감성 분석 결과를 주가 데이터에 결합함으로써 다음과 같은 이점을 얻을 수 있다:
   - **즉각적인 반응성**: 주가의 급격한 변동성이 예측에 반영될 수 있다. 
   - **정확성 강화**: 주가 데이터와 뉴스 감성을 결합하여 예측 모델이 주가의 움직임에 대한 더 정확한 평가를 내릴 수 있다.
  
---

#### 3. BERT 감성 분석의 장점과 주가 예측에서의 역할

BERT를 통한 감성 분석은 주가 예측에서 다음과 같은 장점을 제공한다:
   - **텍스트 이해 능력**: BERT는 자연어 텍스트에서 중요한 의미를 추출해 감성 분석을 수행하기 때문에, 단순 키워드 분석보다 더 깊은 인사이트를 제공한다.
   - **주가와의 상관 관계 반영**: 뉴스에서 감지된 긍정/부정 감성은 주가의 단기 변동에 영향을 미치는 요소로 작용한다.
   - **확장성과 재사용성**: 감성 분석 결과를 저장하고 재활용할 수 있어, 새로 뉴스 데이터를 처리할 필요 없이 빠르게 모델 학습에 반영할 수 있다.

---

이와 같이 BERT 모델은 뉴스 데이터의 감성 분석을 수행하여 주가 예측 모델에 중요한 인풋으로 사용된다. 이를 통해 LSTM이 제공하는 시계열 예측 결과에 시장의 정서적 요인을 반영하여, 더욱 신뢰성 있는 예측을 도출할 수 있다.

</details>

---

### 11. 학습 및 검증 전략

- **손실 함수 (Loss Function)**: 평균 절대 오차(MAE)를 계산하는 `L1Loss`와 `MSELoss`, `SmoothL1Loss` 등을 사용하여 예측값과 실제값 간의 차이를 최소화하도록 학습한다.    
- **최적화 함수 (Optimizer)**: **AdamW** 최적화 함수를 사용하여 학습을 안정화하고 과적합을 방지하기 위해 weight decay를 적용하였다.
- **스케줄러 (Scheduler)**: **StepLR 스케줄러**를 적용하여 일정 에폭마다 학습률을 조정해 모델의 학습 성능을 높였다.

---

### 12. Ray 기반의 분산 학습 및 하이퍼파라미터 최적화

- **Ray를 통한 하이퍼파라미터 최적화**: 하이퍼파라미터 튜닝을 자동화하고 최적의 조합을 찾기 위해 **Ray Tune**을 활용하여 최적의 LSTM 레이어 수, 학습률, 드롭아웃 확률 등을 탐색하였다.
- **분산 데이터 관리**: `ray.put`을 사용하여 뉴스 데이터를 GPU와 분산 학습 환경에 적절하게 배치하고, 이를 실험마다 재활용하여 효율성을 높였다.

---

### 13. GPU 최적화 및 메모리 관리

- **GPU 메모리 관리**: 학습 도중 필요하지 않은 메모리를 해제하기 위해 `torch.cuda.empty_cache()`를 주기적으로 호출하여 GPU 메모리를 최적화하였다.
- **가비지 컬렉션**: `gc.collect()`를 통해 사용하지 않는 CPU 메모리를 정리하여 메모리 누수를 방지하고 학습 속도를 유지하였다.

---

### 14. BERT 토크나이저와 감성 분석 결과 저장

- **BERT 토크나이저**: BERT의 토크나이저를 사용하여 뉴스 데이터를 텍스트 벡터로 변환하고, 이를 통해 감성 분석을 수행하여 긍정/부정 레이블을 예측하였다.
- **결과 데이터 저장 및 재활용**: 감성 분석 결과를 CSV 파일로 저장하고, 모델이 다시 실행될 때 기존 데이터를 불러와 재활용할 수 있도록 설계하였다.

---


## 모델 성능

### 단순 주기 모델

- Accuracy: 0.5138  
- Precision: 0.5966  
- Recall: 0.5504  
- F1-score: 0.5726  
- AUC: 0.5055  
- MCC: 0.01

<details>
  <summary style="font-size: 1.2em;">상세 성과 지표</summary> </br>
    <img src="img/성능지표자료1.png" width="500"/>
    <img src="img/단순주기강화모델.png" width="500"/>
    <img src="img/실제와예측그래프비교.png" width="500"/>
    <img src="img/이동평균선기준정확도.png" width="500"/>
</details>

### 주기 강화 모델

- Accuracy: 0.5691
- Precision: 0.5000
- Recall: 0.5185
- F1-score: 0.5091
- AUC: 0.5630
- MCC: 0.15

<details>
  <summary style="font-size: 1.2em;">상세 성과 지표</summary> </br>
    <img src="img/주기강화모델.png" width="500"/>
    <img src="img/실제와예측그래프-주기강화모델.png" width="500"/>
</details>

## 모델 한계

1. **정확도(Accuracy)가 낮은 편**  
   - **문제점**: 정확도가 약 57%로, 주식 시장 예측에서 예측 성공률이 낮은 편이다.
   - **원인**:
     - **비대칭 데이터**: 주식 예측 문제는 상승과 하락 비율이 일정하지 않아 특정 클래스에 편향될 수 있다.
     - **특징의 제한**: 단순한 주가 데이터와 뉴스 감성 분석만을 사용하고, 더 넓은 범위의 경제 및 기술적 지표를 적용하였으나, 투자 패턴에 관한 자료를 입력하지 않아 상승/하락 지점을 찾는 것에 어려움을 겪는 것으로 판단된다.

2. **정밀도(Precision)와 재현율(Recall)**
   - **문제점**: 정밀도와 재현율이 각각 0.5와 0.52로, 두 값이 모두 낮다. 이는 전반적으로 주가 상승/하락을 잘못 예측하는 경향이 있음을 나타낸다.
   - **원인**:
     - **데이터 불균형**: 상승 또는 하락의 빈도가 비대칭적일 경우 모델이 특정 클래스에 치우쳐 학습할 수 있다.
     - **뉴스 감성 분석의 한계**: 뉴스 감성 분석 결과가 상승/하락 예측에 정확히 기여하지 못하고, 과대평가되거나 과소평가되는 것으로 판단된다.

3. **F1 점수의 한계**
   - **문제점**: F1 점수가 낮은 편이며, 이는 모델이 상승/하락 예측에서 전반적인 정확성과 조화로운 성능을 가지지 못하고 있음을 시사한다.
   - **원인**:
     - **입력 데이터의 제한성**: 감성 분석을 추가하여 입력 데이터를 다변화했지만, 추가적으로 다른 투자 기술 데이터가 필요한 것으로 보인다.
     - **LSTM의 한계**: 주가 데이터는 많은 불확실성을 포함하고 있어, LSTM 단일 모델로는 시장의 급변하는 동향을 모두 반영하기 어려울 수 있다.

4. **AUC 값이 낮은 수준**
   - **문제점**: AUC(ROC 곡선 하의 면적)가 0.563으로 낮은 편으로, 예측에 대해 혼동 행렬의 TPR(참 양성 비율)과 FPR(거짓 양성 비율)을 명확하게 구분하지 못함을 의미한다.
   - **원인**:
     - **분류 임계값 미세 조정 미비**: 분류 모델의 임계값을 조정해 상승/하락 간의 균형을 맞춰야 할 필요성이 있을 수 있다.
     - **감성 분석 정확도 부족**: 뉴스 감성 분석이 모든 뉴스의 주가 영향력을 정확히 반영하지 못하여, 감성분석으로 인해 오히려 AUC 값이 낮아지는 경향이 있다.

5. **매튜스 상관계수(MCC) 한계**
   - **문제점**: MCC가 0.15로 낮은 편에 속한데, 이는 features가 target의 상승/하락 예측의 상관관계가 약함을 의미한다. 특히 불균형한 데이터셋에서 MCC는 중요한 지표가 되며, 낮은 값은 모델의 전반적인 분류 성능이 미흡함을 나타난다.
   - **원인**:
     - **불균형 데이터셋**: 상승과 하락 클래스가 균형을 이루지 못할 경우 MCC가 낮게 나타난다.
     - **과적합 또는 과소적합**: 데이터에 대해 모델이 적절히 학습하지 못했을 가능성이 있으며, 이는 드롭아웃 비율, 학습률 조정, 학습 에폭 등 모델의 하이퍼파라미터 튜닝이 필요함을 시사한다.

6. **뉴스 감성 분석의 제한적 기여**
   - **문제점**: 뉴스 감성 분석 결과가 주가 예측에 명확히 기여하지 않는 경우, 긍정적/부정적 뉴스의 단순 분류는 시장에 미치는 영향을 충분히 반영하지 못할 수 있다.
   - **원인**:
     - **뉴스와 주가 변동 간의 상관관계 약화**: 뉴스가 주가에 항상 영향을 미치는 것은 아니므로, 뉴스에 적용되는 가중치를 조절할 필요가 있다.
     - **특정 업종 또는 사건에 대한 감성 분석 오류**: 특정 사건(예: 전쟁, 경제 제재 등)에 대한 뉴스의 감성 분석이 잘못 이루어질 경우, 모델 예측에 부정적인 영향을 미칠 수 있다.

7. **장기 추세 및 단기 변동 반영 부족**
   - **문제점**: LSTM 모델은 장기적인 추세를 파악하는 데 유리하나, 주식 시장의 단기 변동성을 완벽하게 반영하지 못할 수 있다.
   - **원인**:
     - **데이터 윈도우 크기의 부적절성**: 윈도우 크기를 너무 크게 설정하면 단기 변동이 희석될 수 있고, 너무 작게 설정하면 장기 추세를 놓칠 수 있다.

8. **하이퍼파라미터 튜닝 부족**
   - **문제점**: 드롭아웃 비율, 학습률 등 하이퍼파라미터를 추가로 튜닝하여 모델 성능을 개선할 여지가 있다.
   - **원인**:
     - **하이퍼파라미터 최적화 부족**: Ray Tune 등의 튜닝 도구를 통해 최적의 학습률, 드롭아웃 비율 등을 모델이 탐색하지 않았거나, 적절한 설정을 찾지 못했을 가능성이 있다.

9. **모델 해석 가능성 부족**
   - **문제점**: 주식 예측 모델은 신뢰성과 해석 가능성이 중요하지만, 현재 모델은 그저 상승/하락만 예측하며 왜 특정 예측을 했는지 설명하지 못한다.
   - **원인**:
     - **설명 가능성 부족**: 예측 이유를 설명하기 위해 SHAP(Shapley Additive Explanations)나 LIME(Local Interpretable Model-Agnostic Explanations)와 같은 해석 가능한 AI 기법을 적용하지 않았다.

10. **과적합 가능성**
    - **문제점**: 드롭아웃을 통해 과적합을 방지하려 했지만, 여전히 훈련 데이터에서 과적합이 발생할 수 있다.
    - **원인**:
      - **데이터 불균형**: 학습 데이터에 특정 시점에 대한 데이터가 과도하게 포함되어, 모델이 특정 패턴에 과도하게 학습될 가능성이 있다.
      - **훈련 에폭 수**: 훈련 에폭 수가 많아 과적합될 위험이 있으며, 이를 해결하기 위해 조기 종료(Early Stopping)를 적절히 설정해야 한다.

---

## 한계 극복 방안

1. **정확도(Accuracy) 개선 방안**
   - **모델 앙상블**: LSTM 외에 GRU, Transformer 등의 모델을 결합하여 예측 정확도를 높입니다. 앙상블을 통해 각각의 모델이 포착하지 못한 패턴을 보완할 수 있다.

2. **정밀도(Precision)와 재현율(Recall)의 불균형 해소 방안**
   - **가중치 조정**: 클래스 불균형을 해소하기 위해 손실 함수에서 하락 클래스에 높은 가중치를 부여하여 모델이 하락 클래스를 더 잘 예측하도록 유도한다.
   - **주가 변동성 분석 강화**: 단기적인 뉴스나 이벤트가 주가 변동에 미치는 영향을 고려하여, 특정 구간에서는 뉴스 데이터를 더 강조하도록 모델 구조를 조정한다.

3. **F1 점수 개선 방안**
   - **하이퍼파라미터 최적화**: 드롭아웃 비율, 학습률, 배치 크기 등의 하이퍼파라미터를 `Ray Tune`이나 `Optuna` 등을 통해 최적화하여 F1 점수를 높일 수 있다.
   - **데이터 증강**: 데이터의 수가 부족하다면, 시뮬레이션을 통해 유사한 주가 데이터를 생성하여 학습 데이터를 증가시켜 모델의 일반화 성능을 높힌다.

4. **AUC 값 개선 방안**
   - **임계값 튜닝**: 분류 임계값(threshold)을 조정하여 FPR과 TPR의 균형을 맞춤으로써 AUC 점수를 개선할 수 있다. `GridSearch`를 통해 최적의 임계값을 찾는다.
   - **감성 분석의 정교화**: 뉴스 데이터 감성 분석의 정확도를 높이기 위해 BERT 대신 더 복잡한 `FinBERT`와 같은 금융 특화 모델을 사용하여 금융 뉴스의 미세한 감성을 포착한다.
   - **경제 이벤트 인지 강화**: 주가에 영향을 주는 특정 이벤트(예: 실적 발표, 정책 변화)를 감지하는 기능을 추가하여, 뉴스와 주가 간의 상관관계를 강화한다.

5. **MCC 개선 방안**
   - **클래스 불균형 해결**: 상승과 하락 데이터가 균형을 이루도록 클래스 비율을 조정하거나, 가중치를 부여하여 불균형의 영향을 줄인다.
   - **피쳐 엔지니어링 강화**: 주가 데이터와 뉴스 데이터를 결합할 때, 특정 피쳐(예: 뉴스의 중요도, 주가의 변동성)가 주가 예측에 기여할 수 있도록 강화한다.
   - **이벤트 기반의 데이터 필터링**: 특정 이벤트가 포함된 뉴스만을 학습에 사용하여, 예측 성능에 긍정적인 영향을 줄 수 있도록 한다.

6. **뉴스 감성 분석의 기여도 강화 방안**
   - **키워드 필터링**: "급등", "급락", "호실적" 등 주가에 큰 영향을 줄 수 있는 핵심 키워드를 감지하여, 중요한 뉴스에 더 큰 가중치를 부여한다.
   - **뉴스 주제 분류**: 뉴스 감성 외에도 주제 분류를 통해 주가에 직접적인 영향을 미치는 뉴스(예: 경제, 정치)를 강조하여 학습에 반영한다.

7. **장기 추세와 단기 변동성 반영 방안**
   - **단기 변동성 추가 모델**: 장기 예측을 위해서는 LSTM을 사용하고, 단기 예측에는 CNN 모델을 사용하여 각 모델의 강점을 활용한다.
   - **다중 윈도우 방식 사용**: `window_size`를 다중으로 설정해 단기 및 장기 패턴을 동시에 학습한다.
   - **순환 구조 추가**: 순환구조(예: ConvLSTM)를 도입해 단기와 장기 주가의 변동성을 더 잘 반영할 수 있도록 모델을 구성한다.

8. **하이퍼파라미터 최적화 방안**
   - **Grid Search나 Bayesian Optimization 사용**: 파라미터 범위를 넓혀서 보다 정밀하게 최적의 파라미터 조합을 찾는다.
   - **Dropout 비율 세밀 조정**: 드롭아웃 비율을 단계적으로 줄이거나 증가시키면서, 최적의 과적합 방지 비율을 찾는다.

9. **모델 해석 가능성 강화 방안**
   - **SHAP 또는 LIME을 통한 설명 가능성 추가**: SHAP과 LIME 라이브러리를 사용하여 예측의 원인을 설명하고, 뉴스와 주가 데이터의 영향을 분석하여 예측 이유를 시각화한다.
   - **Attention 메커니즘 도입**: LSTM의 `Attention` 메커니즘을 추가하여, 모델이 특정 뉴스나 주가 변동에 더 큰 가중치를 부여하도록 하여 해석 가능성을 높힌다.
   - **주가 변동과 뉴스 데이터의 관계 시각화**: 예측된 주가와 관련된 뉴스의 감성 분석 결과를 그래프로 시각화하여 이해하기 쉽게 표시한다.

10. **과적합 방지 및 일반화 성능 강화 방안**
    - **Early Stopping 세밀화**: 조기 종료 조건을 다양화하여, 일정 에폭 동안의 검증 성능 변동을 기준으로 훈련을 멈추는 방식을 도입한다.
    - **교차 검증**: K-Fold 교차 검증을 통해 모델의 일반화 성능을 평가하고, 데이터 편향을 줄인다.
    - **더 큰 데이터셋 활용**: 데이터셋의 크기를 키우기 위해 다양한 기간의 주가 및 뉴스 데이터를 추가로 수집하여 학습 데이터의 다양성을 확보한다.

---

### 종합적인 성능 향상 전략

1. **모델 앙상블 및 멀티 모델 접근**: LSTM과 CNN, Transformer 등을 결합한 멀티 모델 또는 앙상블 모델로 성능을 최적화한다.
2. **주가 데이터와 뉴스 데이터 비율 조정**: 뉴스 데이터가 주가 데이터에 과하게 의존하지 않도록, 두 데이터의 비율을 적절히 조정하여 균형 있게 학습시킨다.
3. **과거 주요 이벤트 데이터셋 활용**: 금융 위기, 팬데믹 등 주요 이벤트가 포함된 과거 데이터셋을 추가하여 예측 성능을 높힌다.

# 참고문헌

- 적을까 말까...?
